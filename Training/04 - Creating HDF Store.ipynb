{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating HDF store\n",
    "This script creates an HDF5 file based on the data from previous steps. The HDF5 file enables training on a large data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data_path = 'AggregatedData'\n",
    "HDF5_PATH = \"data.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(s):\n",
    "    with open(\"create_hdf5_log.txt\", \"a\") as myfile:\n",
    "        myfile.write(\"[\" + str(datetime.now()) + \"] \" + s + \"\\n\")\n",
    "    print(\"[\" + str(datetime.now()) + \"] \" + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSizeXh = 25.0 / 2\n",
    "gridSizeYh = 25.0 / 2\n",
    "gridSizeZo = 25 - 5\n",
    "\n",
    "def getLabelCoordinates(df):\n",
    "    # sort the data to the right order and remove all R_Shape data\n",
    "    df = df[df['label'].str.split('_').str[1] != \"R\"].copy(deep=True)\n",
    "    \n",
    "    df.label = pd.Categorical(df.label, \n",
    "                          categories=[\"R_Thumb_Fn\", \"R_Thumb_DIP\", \"R_Thumb_PIP\", \"R_Thumb_MCP\",\n",
    "                                     \"R_Index_Fn\", \"R_Index_DIP\", \"R_Index_PIP\", \"R_Index_MCP\",\n",
    "                                     \"R_Middle_Fn\", \"R_Middle_DIP\", \"R_Middle_PIP\", \"R_Middle_MCP\",\n",
    "                                     \"R_Ring_Fn\", \"R_Ring_DIP\", \"R_Ring_PIP\", \"R_Ring_MCP\",\n",
    "                                     \"R_Little_Fn\", \"R_Little_DIP\", \"R_Little_PIP\", \"R_Little_MCP\",\n",
    "#                                      \"R_R_Shape_1\", \"R_R_Shape_2\", \"R_R_Shape_3\", \"R_R_Shape_4\", \n",
    "                                      \"R_Wrist\",\n",
    "\n",
    "                                     \"L_Thumb_Fn\", \"L_Thumb_DIP\", \"L_Thumb_PIP\", \"L_Thumb_MCP\",\n",
    "                                     \"L_Index_Fn\", \"L_Index_DIP\", \"L_Index_PIP\", \"L_Index_MCP\",\n",
    "                                     \"L_Middle_Fn\", \"L_Middle_DIP\", \"L_Middle_PIP\", \"L_Middle_MCP\",\n",
    "                                     \"L_Ring_Fn\", \"L_Ring_DIP\", \"L_Ring_PIP\", \"L_Ring_MCP\",\n",
    "                                     \"L_Little_Fn\", \"L_Little_DIP\", \"L_Little_PIP\", \"L_Little_MCP\",\n",
    "#                                      \"L_R_Shape_1\", \"L_R_Shape_2\", \"L_R_Shape_3\", \"L_R_Shape_4\", \n",
    "                                      \"L_Wrist\"],\n",
    "                          ordered=True)\n",
    "\n",
    "    df.sort_values('label', inplace=True)\n",
    "    \n",
    "    groups = df.groupby('time')\n",
    "\n",
    "    coordinates = []\n",
    "    size = len(groups)\n",
    "    for name,group in groups:\n",
    "        # filter outliers\n",
    "        if group.XRot.abs().max() > gridSizeXh:\n",
    "            size = size - 1\n",
    "            continue\n",
    "        if group.YRot.abs().max() > gridSizeYh:\n",
    "            size = size - 1\n",
    "            continue\n",
    "        if group.ZRot.abs().max() > gridSizeZo:\n",
    "            size = size - 1\n",
    "            continue\n",
    "        for index, row in group.iterrows():\n",
    "           coordinates.append(row.XRot)\n",
    "           coordinates.append(row.YRot)\n",
    "           coordinates.append(row.ZRot)\n",
    "\n",
    "    coordinates = np.reshape(coordinates, (size * 2, 63))\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareForGrid(coordinates):\n",
    "    coordinates = coordinates.reshape(-1, 21, 3)\n",
    "    # coordinates in mm\n",
    "    coordinates = np.around(coordinates * 1000)\n",
    "    coordinates = coordinates.astype(np.int16)\n",
    "    \n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_hdf(hdf, df, set_name):\n",
    "    groupName = set_name\n",
    "    pGroup = None\n",
    "    groupExists = \"/\" + groupName in hdf\n",
    "\n",
    "    if not (groupExists):\n",
    "        pGroup = hdf.create_group(groupName)\n",
    "    else:\n",
    "        pGroup = hdf[\"/\" + groupName]\n",
    "    \n",
    "    # get labels\n",
    "    log(\"Computing Label Coordinates\")\n",
    "    # coordinates in m\n",
    "    labelCoordinates = getLabelCoordinates(df)\n",
    "    # coordinates in mm\n",
    "    preaparedData = prepareForGrid(labelCoordinates)\n",
    "    \n",
    "    \n",
    "    # shuffle\n",
    "    shuffle = np.arange(preaparedData.shape[0])\n",
    "    np.random.shuffle(shuffle)\n",
    "    labelCoordinates = labelCoordinates[shuffle]\n",
    "    preaparedData = preaparedData[shuffle]\n",
    "    \n",
    "    if not (groupExists):\n",
    "        pGroup.create_dataset(\"data\", data=preaparedData, maxshape=(None, 21, 3), chunks=True)\n",
    "        pGroup.create_dataset(\"labels\", data=labelCoordinates, maxshape=(None, 63), chunks=True)\n",
    "    else:\n",
    "        \n",
    "        pGroup[\"data\"].resize((pGroup[\"data\"].shape[0] + preaparedData.shape[0]), axis = 0)\n",
    "        pGroup[\"data\"][-preaparedData.shape[0]:] = preaparedData\n",
    "        pGroup[\"labels\"].resize((pGroup[\"labels\"].shape[0] + labelCoordinates.shape[0]), axis = 0)\n",
    "        pGroup[\"labels\"][-labelCoordinates.shape[0]:] = labelCoordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new storage for writing.\n",
      "[2018-11-20 23:54:43.870380] P07: Reading dataframe for test.\n",
      "[2018-11-20 23:54:45.391459] P07: Adding to HDF.\n",
      "[2018-11-20 23:54:45.392599] Computing Label Coordinates\n",
      "[2018-11-21 00:02:16.646143] Inverting Y-Values\n",
      "[2018-11-21 00:02:16.686890] Computing Label Coordinates\n",
      "[2018-11-21 00:09:44.662316] Finished\n"
     ]
    }
   ],
   "source": [
    "if Path(HDF5_PATH).is_file():\n",
    "    print(\"Open storage for appending.\")\n",
    "    hdf = h5py.File(HDF5_PATH, mode='a')\n",
    "else:\n",
    "    print(\"Creating new storage for writing.\")\n",
    "    hdf = h5py.File(HDF5_PATH, mode='w')\n",
    "    \n",
    "training_participants = [\"03\", \"05\", \"09\", \"11\", \"12\", \"13\", \"15\", \"16\", \"18\", \"19\", \"21\"]\n",
    "for i in training_participants:\n",
    "    log(\"P\" + str(i) + \": Reading dataframe for training.\")\n",
    "    df = pd.read_pickle(aggregated_data_path + \"/\" + str(i) + \".pkl\")\n",
    "    log(\"P\" + str(i) + \": Adding to HDF.\")\n",
    "    add_to_hdf(hdf, df, \"train\")\n",
    "    log(\"Inverting Y-Values\")\n",
    "    df['YRot'] = -df['YRot']\n",
    "    add_to_hdf(hdf, df, \"train\")\n",
    "\n",
    "test_participants = [\"07\", \"06\", \"14\"] # randomly picked from the list of participants\n",
    "for i in test_participants:\n",
    "    log(\"P\" + str(i) + \": Reading dataframe for test.\")\n",
    "    df = pd.read_pickle(aggregated_data_path + \"/\" + str(i) + \".pkl\")\n",
    "    log(\"P\" + str(i) + \": Adding to HDF.\")\n",
    "    add_to_hdf(hdf, df, \"test\")\n",
    "    log(\"Inverting Y-Values\")\n",
    "    df['YRot'] = -df['YRot']\n",
    "    add_to_hdf(hdf, df, \"test\")\n",
    "        \n",
    "validation_participants = [\"08\", \"02\", \"04\", \"10\"] # randomly picked from the list of participants\n",
    "for i in validation_participants:\n",
    "    log(\"P\" + str(i) + \": Reading dataframe for validation.\")\n",
    "    df = pd.read_pickle(aggregated_data_path + \"/\" + str(i) + \".pkl\")\n",
    "    log(\"P\" + str(i) + \": Adding to HDF.\")\n",
    "    add_to_hdf(hdf, df, \"validation\")\n",
    " \n",
    "hdf.close()\n",
    "log(\"Finished\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf = h5py.File(HDF5_PATH, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 2083884\n",
      "Test samples: 534252\n",
      "Validation samples: 291766\n",
      "Total samples: 2909902\n"
     ]
    }
   ],
   "source": [
    "print(\"Training samples:\", hdf[\"train/data\"].shape[0])\n",
    "print(\"Test samples:\", hdf[\"test/data\"].shape[0])\n",
    "print(\"Validation samples:\", hdf[\"validation/data\"].shape[0])\n",
    "print(\"Total samples:\", hdf[\"train/data\"].shape[0]+hdf[\"test/data\"].shape[0]+hdf[\"validation/data\"].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
